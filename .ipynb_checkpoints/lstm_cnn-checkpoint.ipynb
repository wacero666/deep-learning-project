{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate data preparation\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "import os\n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps, n_lap):\n",
    "\tX = list()\n",
    "\tfor i in range(0, len(sequences), n_lap):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the dataset\n",
    "\t\tif end_ix > len(sequences):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x = sequences[i:end_ix, :]\n",
    "\t\tX.append(seq_x)\n",
    "\t\t\n",
    "\treturn array(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pairs = []\n",
    "y = np.loadtxt(\"./pairs/y.txt\")\n",
    "def get_set(path, pairs):\n",
    "    for root, dirnames, filenames in os.walk(path):\n",
    "\n",
    "        pair = [] #[song1, song2, similarity_class_mapped(0,1)]\n",
    "        if len(filenames) > 1:\n",
    "            for file in filenames:\n",
    "                filepath = os.path.join(root, file)\n",
    "                if \".npy\" in file:\n",
    "                    pair.append(np.load(filepath)) \n",
    "            idx = int(root[19:])\n",
    "            assert(y[idx][0] == idx)\n",
    "            score = y[idx][1]\n",
    "#             if score > 0.3:\n",
    "#                 pair.append(1)\n",
    "#             else:\n",
    "#                 pair.append(0)\n",
    "            pair.append(score)\n",
    "            if (len(pair)>0):\n",
    "                pairs.append(pair)\n",
    "    np.save(\"val_set_score.npy\", np.array(pairs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pairs = []\n",
    "get_set(\"./pairs/validation\",pairs)\n",
    "# for root, dirnames, filenames in os.walk(\"./pairs/test\"):\n",
    "    \n",
    "#     pair_test = [] #[song1, song2, similarity_score]\n",
    "#     if len(filenames) > 1:\n",
    "#         for file in filenames:\n",
    "#             filepath = os.path.join(root, file)\n",
    "#             if \".npy\" in file:\n",
    "#                 pair_test.append(np.load(filepath)) \n",
    "#             if \"y.txt\" in file: \n",
    "#                 pair_test.append(np.loadtxt(filepath))\n",
    "#         pairs_test.append(pair_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00516024"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = np.load(\"val_set_score.npy\")\n",
    "data[99][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 120, 3)\n",
      "(64, 120, 3)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# first data sample\n",
    "print(data[0][0].shape) #first matrix in pair\n",
    "print(data[0][1].shape) #second matrix in pair\n",
    "print(data[0][2]) # score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 20, 64, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = 20 #10seconds\n",
    "n_lap = 10 #5seconds\n",
    "image_x = split_sequences(np.transpose(data[0][0], (1,0,2)), n_steps, n_lap)\n",
    "image_x.shape #n_blocks*n_steps*x_dimension*RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/wanhezhao/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Train a recurrent convolutional network on the IMDB sentiment classification task.\n",
    "\n",
    "Gets to 0.8498 test accuracy after 2 epochs. 41 s/epoch on K520 GPU.\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.datasets import imdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n",
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Embedding\n",
    "max_features = 20000\n",
    "maxlen = 100\n",
    "embedding_size = 128\n",
    "\n",
    "# Convolution\n",
    "kernel_size = 5\n",
    "filters = 64\n",
    "pool_size = 4\n",
    "\n",
    "# LSTM\n",
    "lstm_output_size = 70\n",
    "\n",
    "# Training\n",
    "batch_size = 30\n",
    "epochs = 2\n",
    "\n",
    "'''\n",
    "Note:\n",
    "batch_size is highly sensitive.\n",
    "Only 2 epochs are needed as the dataset is very small.\n",
    "'''\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Build model...')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_size, input_length=maxlen))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "model.add(MaxPooling1D(pool_size=pool_size))\n",
    "model.add(LSTM(lstm_output_size))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
